{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51de22b3-f89e-4bde-947a-b7ec10556133",
   "metadata": {},
   "source": [
    "Будем практиковаться на датасете недвижимости (sklearn.datasets.fetch_california_housing)\n",
    "\n",
    "Ваша задача:\n",
    "1. Создать Dataset для загрузки данных\n",
    "2. Обернуть его в Dataloader\n",
    "3. Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
    "4. Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели\n",
    "\n",
    "train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116a3ee4-b4c9-46fc-9344-c6e305a04516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89ab3a9-c026-4c03-ae91-942f0bd9665e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = fetch_california_housing(as_frame=True)\n",
    "clf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7e915e-683a-466f-ab87-588672c9c2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "An household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surpinsingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54827ec7-8179-42e1-bf9e-6882d3820a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = clf.frame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f388b6-e1fd-4dd7-80d2-6de52ff82fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=['MedHouseVal'])\n",
    "y = data['MedHouseVal']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51bfd6b5-bedd-4762-baa0-d575efa8ddbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15480, 8), (5160, 8), (15480,), (5160,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882fc969-1a5a-43fd-830d-e5577b1d04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = torch.FloatTensor(X_train).float()\n",
    "y_train = torch.FloatTensor(y_train.values).float()\n",
    "\n",
    "X_test = torch.FloatTensor(X_test).float()\n",
    "y_test = torch.FloatTensor(y_test.values).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228176ea-2448-408d-9b4e-40f1fd219f00",
   "metadata": {},
   "source": [
    "1. Создать Dataset для загрузки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81166ad9-b244-4bbc-a087-d86c02c8be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "   \n",
    "    def __init__(self, data, target):\n",
    "        \n",
    "        self.X = data\n",
    "        self.y = target\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.X)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "               \n",
    "        return [self.X[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d727d-d906-45ac-b1df-9dce50f02640",
   "metadata": {},
   "source": [
    "2. Обернуть его в Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e98a523-f0d6-4a97-8a18-b487f566cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data(X_train, y_train)\n",
    "train_loader = DataLoader(train_data,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=0\n",
    "                         )\n",
    "\n",
    "test_data = Data(X_test, y_test)\n",
    "test_loader = DataLoader(test_data,\n",
    "                         batch_size=128,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True,\n",
    "                         num_workers=0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b76c3d9-d40d-4f47-b599-5caca916a068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: tensor([0.1995, 0.6078, 0.0335, 0.0217, 0.1387, 0.0017, 0.6440, 0.3003])\n",
      "target: 1.034000039100647\n"
     ]
    }
   ],
   "source": [
    "print(f'data: {train_data[0][0]}\\ntarget: {train_data[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec7e87-bb37-48c0-b464-5f9ab39109de",
   "metadata": {},
   "source": [
    "3. Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf10c9e-9317-4c9e-b0b2-8a9180f36707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, activation='relu'):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim).cuda()\n",
    "        assert activation in ['relu', 'sigmoid'], 'Activation func should be \"relu\" or \"sigmoid\"!'\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc(x).cuda()\n",
    "        return eval(f'F.{self.activation}')(x)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf4b431-35e6-4e7d-bbc7-e1e9ebc46fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        \n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = Perceptron(input_dim, 4*hidden_dim).cuda()\n",
    "        self.dp1 = nn.Dropout(0.4).cuda()\n",
    "        self.bn1 = nn.BatchNorm1d(4*hidden_dim).cuda()\n",
    "\n",
    "        self.fc2 = Perceptron(4*hidden_dim, 2*hidden_dim).cuda()\n",
    "        self.dp2 = nn.Dropout(0.3).cuda()\n",
    "        self.bn2 = nn.BatchNorm1d(2*hidden_dim).cuda()\n",
    "        \n",
    "        self.fc3 = Perceptron(2*hidden_dim, hidden_dim).cuda()\n",
    "        self.dp3 = nn.Dropout(0.2).cuda()\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim).cuda()\n",
    "        \n",
    "        self.fc4 = Perceptron(hidden_dim, 1).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x).cuda()\n",
    "        x = self.bn1(x).cuda()\n",
    "        x = self.dp1(x).cuda()\n",
    "        \n",
    "        x = self.fc2(x).cuda()\n",
    "        x = self.bn2(x).cuda()\n",
    "        x = self.dp2(x).cuda()\n",
    "        \n",
    "        x = self.fc3(x).cuda()\n",
    "        x = self.bn3(x).cuda()\n",
    "        x = self.dp3(x).cuda()\n",
    "        \n",
    "        x = self.fc4(x).cuda()\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1269025-0d19-40ab-956b-d06981fd380c",
   "metadata": {},
   "source": [
    "4. Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33bd44f9-d270-40f3-aea2-e83228f14859",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FeedForward(8, 1024)\n",
    "\n",
    "optimizer = SGD(net.parameters(), lr=0.005)\n",
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5a7d33-098c-47b4-8285-8a1eafc33bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200] | Step [120/120] | Loss: 0.004 | Train R2: 0.310 | Test R2: 0.512\n",
      "Epoch [40/200] | Step [120/120] | Loss: 0.004 | Train R2: 0.575 | Test R2: 0.594\n",
      "Epoch [60/200] | Step [120/120] | Loss: 0.004 | Train R2: 0.655 | Test R2: 0.631\n",
      "Epoch [80/200] | Step [120/120] | Loss: 0.004 | Train R2: 0.671 | Test R2: 0.660\n",
      "Epoch [100/200] | Step [120/120] | Loss: 0.004 | Train R2: 0.676 | Test R2: 0.662\n",
      "Epoch [120/200] | Step [120/120] | Loss: 0.004 | Train R2: 0.679 | Test R2: 0.654\n",
      "Epoch [140/200] | Step [120/120] | Loss: 0.004 | Train R2: 0.683 | Test R2: 0.664\n",
      "Epoch [160/200] | Step [120/120] | Loss: 0.004 | Train R2: 0.684 | Test R2: 0.668\n",
      "Epoch [180/200] | Step [120/120] | Loss: 0.004 | Train R2: 0.686 | Test R2: 0.668\n",
      "Epoch [200/200] | Step [120/120] | Loss: 0.003 | Train R2: 0.689 | Test R2: 0.678\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "net.train()\n",
    "metrics_train = []\n",
    "metrics_test = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    running_loss, running_items = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        \n",
    "        train_res = net(inputs)\n",
    "        metrics_train.append(r2_score(labels.cpu().detach().numpy(), train_res.cpu().detach().numpy().reshape(-1)))\n",
    "        \n",
    "    if (ep + 1)%20 == 0:  \n",
    "        net.eval()\n",
    "\n",
    "        print(f'Epoch [{ep + 1}/{epochs}] | ' \\\n",
    "              f'Step [{i + 1}/{len(train_loader)}] | ' \\\n",
    "              f'Loss: {running_loss / running_items:.3f} | ' \\\n",
    "              f'Train R2: {sum(metrics_train) / len(metrics_train):.3f} | ', end='')\n",
    "\n",
    "        running_loss, running_items = 0.0, 0.0\n",
    "        metrics_train = []\n",
    "\n",
    "        for i, data in enumerate(test_loader):\n",
    "            test_res = net(data[0].cuda())\n",
    "            metrics_test.append(r2_score(data[1].cpu().detach().numpy(), test_res.cpu().detach().numpy().reshape(-1)))\n",
    "        print(f'Test R2: {sum(metrics_test) / len(metrics_test):.3f}')\n",
    "        metrics_test = []\n",
    "        net.train()\n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147398e0-0bfe-42bd-8bbb-01a81ff11fb2",
   "metadata": {},
   "source": [
    "c опстимизатором SGD метрики сходятся к 200 эпохе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de3f648-70a2-44cd-99ca-a969da0eb1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FeedForward(8, 512)\n",
    "\n",
    "optimizer = Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfea12cc-f8f7-4e0e-bce1-ea1dd0a6ed79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200] | Step [120/120] | Loss: 0.003 | Train R2: 0.628 | Test R2: 0.707\n",
      "Epoch [40/200] | Step [120/120] | Loss: 0.003 | Train R2: 0.730 | Test R2: 0.707\n",
      "Epoch [60/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.755 | Test R2: 0.754\n",
      "Epoch [80/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.765 | Test R2: 0.669\n",
      "Epoch [100/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.769 | Test R2: 0.779\n",
      "Epoch [120/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.784 | Test R2: -11754.423\n",
      "Epoch [140/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.793 | Test R2: -67.210\n",
      "Epoch [160/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.797 | Test R2: -17.778\n",
      "Epoch [180/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.805 | Test R2: 0.622\n",
      "Epoch [200/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.806 | Test R2: -16374.604\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "net.train()\n",
    "metrics_train = []\n",
    "metrics_test = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    running_loss, running_items = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        \n",
    "        train_res = net(inputs)\n",
    "        metrics_train.append(r2_score(labels.cpu().detach().numpy(), train_res.cpu().detach().numpy().reshape(-1)))\n",
    "        \n",
    "    if (ep + 1)%20 == 0:  \n",
    "        net.eval()\n",
    "\n",
    "        print(f'Epoch [{ep + 1}/{epochs}] | ' \\\n",
    "              f'Step [{i + 1}/{len(train_loader)}] | ' \\\n",
    "              f'Loss: {running_loss / running_items:.3f} | ' \\\n",
    "              f'Train R2: {sum(metrics_train) / len(metrics_train):.3f} | ', end='')\n",
    "\n",
    "        running_loss, running_items = 0.0, 0.0\n",
    "        metrics_train = []\n",
    "\n",
    "        for i, data in enumerate(test_loader):\n",
    "            test_res = net(data[0].cuda())\n",
    "            metrics_test.append(r2_score(data[1].cpu().detach().numpy(), test_res.cpu().detach().numpy().reshape(-1)))\n",
    "        print(f'Test R2: {sum(metrics_test) / len(metrics_test):.3f}')\n",
    "        metrics_test = []\n",
    "        net.train()\n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690817d9-a47e-464d-8b57-a766ec09a4d9",
   "metadata": {},
   "source": [
    "С оптимизатором Adam метрики показывают какую-то странную картину на тесте. Единственное вменяемое значение на 160 эпохе. Почему так получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "116d0cc3-9fe2-4039-886e-eb3470d78d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FeedForward(8, 1024)\n",
    "\n",
    "optimizer = RMSprop(net.parameters(), lr=0.005)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a355ceb9-66a7-4adb-af8b-91995b1c8271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200] | Step [120/120] | Loss: 0.004 | Train R2: 0.421 | Test R2: -43624.476\n",
      "Epoch [40/200] | Step [120/120] | Loss: 0.003 | Train R2: 0.663 | Test R2: -11.708\n",
      "Epoch [60/200] | Step [120/120] | Loss: 0.003 | Train R2: 0.754 | Test R2: 0.719\n",
      "Epoch [80/200] | Step [120/120] | Loss: 0.003 | Train R2: 0.766 | Test R2: -1433446.335\n",
      "Epoch [100/200] | Step [120/120] | Loss: 0.003 | Train R2: 0.773 | Test R2: -3370933.260\n",
      "Epoch [120/200] | Step [120/120] | Loss: 0.003 | Train R2: 0.776 | Test R2: 0.709\n",
      "Epoch [140/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.779 | Test R2: -61011456846.788\n",
      "Epoch [160/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.795 | Test R2: -20780077788.041\n",
      "Epoch [180/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.802 | Test R2: -103195589310.460\n",
      "Epoch [200/200] | Step [120/120] | Loss: 0.002 | Train R2: 0.808 | Test R2: -624176.109\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "net.train()\n",
    "metrics_train = []\n",
    "\n",
    "for ep in range(epochs):\n",
    "    running_loss, running_items = 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        \n",
    "        train_res = net(inputs)\n",
    "        metrics_train.append(r2_score(labels.cpu().detach().numpy(), train_res.cpu().detach().numpy().reshape(-1)))\n",
    "        \n",
    "    if (ep + 1)%20 == 0:  \n",
    "        net.eval()\n",
    "\n",
    "        print(f'Epoch [{ep + 1}/{epochs}] | ' \\\n",
    "              f'Step [{i + 1}/{len(train_loader)}] | ' \\\n",
    "              f'Loss: {running_loss / running_items:.3f} | ' \\\n",
    "              f'Train R2: {sum(metrics_train) / len(metrics_train):.3f} | ', end='')\n",
    "\n",
    "        running_loss, running_items = 0.0, 0.0\n",
    "        metrics_train = []\n",
    "\n",
    "        metrics_test = []\n",
    "        for i, data in enumerate(test_loader):\n",
    "            test_res = net(data[0].cuda())\n",
    "            metrics_test.append(r2_score(data[1].cpu().detach().numpy(), test_res.cpu().detach().numpy().reshape(-1)))\n",
    "        print(f'Test R2: {sum(metrics_test) / len(metrics_test):.3f}')\n",
    "        net.train()\n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b1e53-42b9-4502-8371-641852d4b6d7",
   "metadata": {},
   "source": [
    "Периодически сеть показывает очень странные предсказания. Как и в случае с Адамом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c3de9-2af4-4391-896e-fa587c5ffcca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
