{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed1f3a0-085a-49e2-b26a-393d93ce4b06",
   "metadata": {},
   "source": [
    "1. Обучите CNN (самописная) на CIFAR-100.\n",
    "2. Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50.\n",
    "3. *Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50 с аугментацией данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90b2d14c-58c6-4aa6-9bbe-a674ddd05857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4808d2f9-28f0-4ab3-900f-30e0402bf309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.CIFAR100(root='./data/', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9aa834a-8d67-4e8d-a4cf-8404be4deba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnCifar(torch.utils.data.Dataset):\n",
    "   \n",
    "    def __init__(self, init_dataset, transform=None):\n",
    "        self._base_dataset = init_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self._base_dataset[idx][0]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = self._base_dataset[idx][1]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9542b09-915d-4ae2-b590-0519a304e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(Xt):\n",
    "    X_train, X_test = train_test_split(Xt, test_size=0.05, random_state=13)\n",
    "    return X_train, X_test\n",
    "\n",
    "train_dataset, valid_dataset = train_valid_split(dataset)\n",
    "\n",
    "train_dataset = MyOwnCifar(train_dataset,\n",
    "                           transforms.ToTensor()\n",
    "                          )\n",
    "valid_dataset = MyOwnCifar(valid_dataset,\n",
    "                           transforms.ToTensor()\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30692b8-151a-4edd-a4df-c665ce638ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=True, \n",
    "                                           num_workers=0)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4c05bc-d4cd-4689-a458-d0f4421dea2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = dataset.classes\n",
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf834310-810d-456d-98b9-cc1a62433986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size: torch.Size([3, 32, 32])\n",
      "image_tensor:\n",
      "tensor([[[0.6039, 0.6118, 0.6275,  ..., 0.4824, 0.4863, 0.4824],\n",
      "         [0.6353, 0.6431, 0.6510,  ..., 0.5059, 0.5176, 0.5059],\n",
      "         [0.6510, 0.6549, 0.6667,  ..., 0.5216, 0.5333, 0.5216],\n",
      "         ...,\n",
      "         [0.4314, 0.4588, 0.4980,  ..., 0.4588, 0.4902, 0.4510],\n",
      "         [0.4392, 0.4627, 0.4902,  ..., 0.4784, 0.4784, 0.4510],\n",
      "         [0.4392, 0.4588, 0.4745,  ..., 0.4745, 0.4588, 0.4314]],\n",
      "\n",
      "        [[0.6000, 0.6078, 0.6235,  ..., 0.4627, 0.4627, 0.4627],\n",
      "         [0.6314, 0.6392, 0.6471,  ..., 0.4863, 0.4902, 0.4902],\n",
      "         [0.6471, 0.6510, 0.6627,  ..., 0.5020, 0.5059, 0.5020],\n",
      "         ...,\n",
      "         [0.3843, 0.4157, 0.4510,  ..., 0.4118, 0.4431, 0.4039],\n",
      "         [0.3882, 0.4157, 0.4431,  ..., 0.4314, 0.4314, 0.4039],\n",
      "         [0.3922, 0.4118, 0.4275,  ..., 0.4275, 0.4118, 0.3843]],\n",
      "\n",
      "        [[0.6314, 0.6392, 0.6510,  ..., 0.4863, 0.4824, 0.4824],\n",
      "         [0.6627, 0.6706, 0.6784,  ..., 0.5137, 0.5098, 0.5059],\n",
      "         [0.6784, 0.6824, 0.6941,  ..., 0.5255, 0.5255, 0.5255],\n",
      "         ...,\n",
      "         [0.4000, 0.4314, 0.4667,  ..., 0.4196, 0.4510, 0.4118],\n",
      "         [0.4039, 0.4314, 0.4588,  ..., 0.4392, 0.4392, 0.4118],\n",
      "         [0.4078, 0.4275, 0.4431,  ..., 0.4353, 0.4196, 0.3922]]])\n",
      "class: table\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_dataset:\n",
    "    print(f'image size: {image.shape}\\nimage_tensor:\\n{image}\\nclass: {classes[label]}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5359c-7be8-4462-84f2-97b9a8791d62",
   "metadata": {},
   "source": [
    "# Обучите CNN (самописная) на CIFAR-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006d3b60-4b03-4fdd-b587-edf919e7f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(30, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(60, 100, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (bn4): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(100, 150, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (bn5): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dp1): Dropout(p=0.25, inplace=False)\n",
      "  (dp2): Dropout(p=0.2, inplace=False)\n",
      "  (dp3): Dropout(p=0.2, inplace=False)\n",
      "  (fc1): Linear(in_features=400, out_features=250, bias=True)\n",
      "  (fc2): Linear(in_features=450, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=400, out_features=200, bias=True)\n",
      "  (out): Linear(in_features=250, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(3) # 3 input channels\n",
    "        self.conv1 = nn.Conv2d(3, 30, 3) # convolute 3 channels to 25 channels by frame of 3*3\n",
    "                \n",
    "        self.bn2 = nn.BatchNorm2d(30) # batchnorm of 25 channels\n",
    "        self.conv2 = nn.Conv2d(30, 60, 3) # convolute 25 channels to 75 channels by frame of 3*3\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm2d(60) # batchnorm of 75 channels\n",
    "        self.conv3 = nn.Conv2d(60, 100, 2) # convolute 75 channels to 150 channels by frame of 2*2\n",
    "        \n",
    "        self.bn4 = nn.BatchNorm2d(100) # batchnorm of 150 channels\n",
    "        self.conv4 = nn.Conv2d(100, 150, 2) # convolute 150 channels to 300 channels by frame of 2*2\n",
    "        \n",
    "        self.bn5 = nn.BatchNorm2d(150) # batchnorm of 300 channels\n",
    "                \n",
    "        self.dp1 = nn.Dropout(0.25) # dropout for 1 linear with 40% non-trainable params\n",
    "        self.dp2 = nn.Dropout(0.2) # dropout for 2 linear with 30% non-trainable params\n",
    "        self.dp3 = nn.Dropout(0.2) # dropout for 3 linear with 20% non-trainable params\n",
    "        \n",
    "        self.fc1 = nn.Linear(400, 250) # 1th linear layer, 1600 inputs -> 800 outputs\n",
    "        self.fc2 = nn.Linear(450, 200) # 2th linear layer, 800 inputs -> 400 outputs\n",
    "        self.fc3 = nn.Linear(400, 200) # 3th linear layer, 400 inputs -> 200 outputs\n",
    "        self.out = nn.Linear(250, 100) # 4th linear layer, 200 inputs -> 100 outputs\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # 1 layer conv\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # 2 layer conv\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # 3 layer conv\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x, 0.1)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # 4 layer conv\n",
    "        x = self.bn4(x)\n",
    "        # x = self.conv4(x)\n",
    "        # x = F.leaky_relu(x, 0.1)\n",
    "        # x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # noramalization before flatten\n",
    "        # x = self.bn5(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1) # transform x to vector\n",
    "        \n",
    "        # 5 layer linear\n",
    "        x = self.dp1(x) \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # 6 layer linear\n",
    "        # x = self.dp2(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = F.relu(x)\n",
    "        \n",
    "        # 7 layer linear\n",
    "        # x = self.dp3(x)\n",
    "        # x = self.fc3(x)\n",
    "        # x = F.relu(x)\n",
    "        \n",
    "        return self.out(x)\n",
    "       \n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8df5047a-218b-4ec9-8182-85a98c204bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d29d72c-5e17-450b-8c79-ee991077a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]. Step [1/475]. Loss: 0.046. Acc: 0.020. Test acc: 0.012\n",
      "Epoch [1/10]. Step [301/475]. Loss: 0.038. Acc: 0.121. Test acc: 0.164\n",
      "Epoch [2/10]. Step [1/475]. Loss: 0.032. Acc: 0.210. Test acc: 0.193\n",
      "Epoch [2/10]. Step [301/475]. Loss: 0.031. Acc: 0.230. Test acc: 0.256\n",
      "Epoch [3/10]. Step [1/475]. Loss: 0.028. Acc: 0.330. Test acc: 0.261\n",
      "Epoch [3/10]. Step [301/475]. Loss: 0.028. Acc: 0.287. Test acc: 0.276\n",
      "Epoch [4/10]. Step [1/475]. Loss: 0.024. Acc: 0.360. Test acc: 0.318\n",
      "Epoch [4/10]. Step [301/475]. Loss: 0.027. Acc: 0.322. Test acc: 0.310\n",
      "Epoch [5/10]. Step [1/475]. Loss: 0.023. Acc: 0.390. Test acc: 0.326\n",
      "Epoch [5/10]. Step [301/475]. Loss: 0.025. Acc: 0.352. Test acc: 0.331\n",
      "Epoch [6/10]. Step [1/475]. Loss: 0.023. Acc: 0.370. Test acc: 0.339\n",
      "Epoch [6/10]. Step [301/475]. Loss: 0.024. Acc: 0.373. Test acc: 0.333\n",
      "Epoch [7/10]. Step [1/475]. Loss: 0.025. Acc: 0.380. Test acc: 0.343\n",
      "Epoch [7/10]. Step [301/475]. Loss: 0.024. Acc: 0.385. Test acc: 0.352\n",
      "Epoch [8/10]. Step [1/475]. Loss: 0.024. Acc: 0.360. Test acc: 0.362\n",
      "Epoch [8/10]. Step [301/475]. Loss: 0.023. Acc: 0.401. Test acc: 0.343\n",
      "Epoch [9/10]. Step [1/475]. Loss: 0.020. Acc: 0.510. Test acc: 0.374\n",
      "Epoch [9/10]. Step [301/475]. Loss: 0.022. Acc: 0.416. Test acc: 0.364\n",
      "Epoch [10/10]. Step [1/475]. Loss: 0.022. Acc: 0.420. Test acc: 0.363\n",
      "Epoch [10/10]. Step [301/475]. Loss: 0.022. Acc: 0.424. Test acc: 0.369\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "net.train()\n",
    "\n",
    "for epoch in range(num_epochs):  \n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "        \n",
    "        # выводим статистику о процессе обучения\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            net.eval()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
    "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "\n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            for i, data in enumerate(valid_loader):\n",
    "            \n",
    "                test_outputs = net(data[0].cuda())\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1].cuda() == torch.max(test_outputs, 1)[1]).sum()\n",
    "            \n",
    "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2680fcaa-168f-4bb3-8bb9-426cf20945a4",
   "metadata": {},
   "source": [
    "Путем манипуляций с самописной сетью удалось получить метрику около 0.38. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8194ce0-07e3-48b5-a89c-07370a548c75",
   "metadata": {},
   "source": [
    "# Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fd94176-9350-44c3-a1a2-df91d1dc1562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36dc244e-997c-441e-b573-1b5953d909d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50424a0c-a692-4861-892f-fceca288789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e141b786-a3ae-4388-8365-c0565772006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model.cuda(), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d43e7d7-792e-439d-83d2-4df90a041ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in list(model.parameters())[:]:\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be4ccd48-5068-40c7-a46a-5d5ed98c8c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model.cuda(), input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be58e636-a3de-408a-9984-fc1b0397a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dp1 = nn.Dropout(0.45)\n",
    "model.fc = nn.Linear(2048, 100)\n",
    "# summary(model.cuda(), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7aecb521-1631-4b1f-b466-fe1d5912b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_actions = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
    "                                  )\n",
    "valid_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
    "                                     )\n",
    "\n",
    "train_dataset, valid_dataset = train_valid_split(dataset)\n",
    "\n",
    "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
    "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bec533bf-24a6-45ea-aa42-b313e06af34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]. Step [1/475]. Loss: 0.048. Acc: 0.000. Test acc: 0.008\n",
      "Epoch [1/10]. Step [301/475]. Loss: 0.047. Acc: 0.009. Test acc: 0.005\n",
      "Epoch [2/10]. Step [1/475]. Loss: 0.046. Acc: 0.020. Test acc: 0.007\n",
      "Epoch [2/10]. Step [301/475]. Loss: 0.047. Acc: 0.009. Test acc: 0.006\n",
      "Epoch [3/10]. Step [1/475]. Loss: 0.047. Acc: 0.010. Test acc: 0.006\n",
      "Epoch [3/10]. Step [301/475]. Loss: 0.047. Acc: 0.009. Test acc: 0.007\n",
      "Epoch [4/10]. Step [1/475]. Loss: 0.048. Acc: 0.000. Test acc: 0.007\n",
      "Epoch [4/10]. Step [301/475]. Loss: 0.047. Acc: 0.009. Test acc: 0.007\n",
      "Epoch [5/10]. Step [1/475]. Loss: 0.047. Acc: 0.030. Test acc: 0.005\n",
      "Epoch [5/10]. Step [301/475]. Loss: 0.047. Acc: 0.009. Test acc: 0.007\n",
      "Epoch [6/10]. Step [1/475]. Loss: 0.048. Acc: 0.000. Test acc: 0.006\n",
      "Epoch [6/10]. Step [301/475]. Loss: 0.047. Acc: 0.010. Test acc: 0.006\n",
      "Epoch [7/10]. Step [1/475]. Loss: 0.047. Acc: 0.010. Test acc: 0.007\n",
      "Epoch [7/10]. Step [301/475]. Loss: 0.047. Acc: 0.008. Test acc: 0.006\n",
      "Epoch [8/10]. Step [1/475]. Loss: 0.047. Acc: 0.030. Test acc: 0.007\n",
      "Epoch [8/10]. Step [301/475]. Loss: 0.047. Acc: 0.008. Test acc: 0.008\n",
      "Epoch [9/10]. Step [1/475]. Loss: 0.047. Acc: 0.020. Test acc: 0.006\n",
      "Epoch [9/10]. Step [301/475]. Loss: 0.047. Acc: 0.010. Test acc: 0.008\n",
      "Epoch [10/10]. Step [1/475]. Loss: 0.048. Acc: 0.000. Test acc: 0.007\n",
      "Epoch [10/10]. Step [301/475]. Loss: 0.047. Acc: 0.010. Test acc: 0.007\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):  \n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "        \n",
    "        # выводим статистику о процессе обучения\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            model.eval()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
    "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "\n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            for i, data in enumerate(valid_loader):\n",
    "            \n",
    "                test_outputs = model(data[0].cuda())\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1].cuda() == torch.max(test_outputs, 1)[1]).sum()\n",
    "            \n",
    "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd84d8-c067-4475-bdcd-d4e05ae6a9b4",
   "metadata": {},
   "source": [
    "почему-то очень все плохо. Даже самописаня модель лучше справилась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e682f37-c4db-43aa-9eba-16bc183dd78c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
